# Hand Helm - Real-time Hand Gesture Recognition System

A computer vision project that uses hand gestures to control your computer, built with OpenCV, MediaPipe, and machine learning.

## ğŸ¯ Features

- **Real-time Hand Detection**: Uses MediaPipe for robust hand landmark detection
- **Gesture Recognition**: Machine learning models to classify hand gestures
- **Computer Control**: Execute actions like media control, presentation navigation, and cursor control
- **Customizable Actions**: Map gestures to custom computer actions
- **High Performance**: Optimized for real-time processing

## ğŸ® Supported Gestures

- Fist
- Open Palm
- Thumbs Up
- Thumbs Down
- Peace Sign
- OK Sign
- Point Up
- Point Down
- Point Left
- Point Right

## ğŸ› ï¸ Tech Stack

- **Computer Vision**: OpenCV, MediaPipe
- **Machine Learning**: TensorFlow, scikit-learn
- **Data Processing**: NumPy, Pandas
- **System Control**: pyautogui, keyboard, pynput
- **Visualization**: Matplotlib, Seaborn

## ğŸš€ Quick Start

1. **Clone the repository**:
```bash
git clone https://github.com/AdityaKuchhal/HandHelm.git
cd HandHelm
```

2. **Install dependencies**:
```bash
pip install -r requirements.txt
```

3. **Run the application**:
```bash
python run.py
```

## ğŸ“ Project Structure

```
hand-helm/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # Raw gesture data (gitignored)
â”‚   â””â”€â”€ processed/     # Preprocessed data (gitignored)
â”œâ”€â”€ models/            # Trained models (gitignored)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py      # Configuration settings
â”‚   â”œâ”€â”€ data_collection.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ gesture_detection.py
â”‚   â”œâ”€â”€ gesture_classification.py
â”‚   â”œâ”€â”€ computer_control.py
â”‚   â””â”€â”€ app.py         # Main application
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_management.py
â”‚   â”œâ”€â”€ demo_data_collection.py
â”‚   â””â”€â”€ test_data_collection.py
â”œâ”€â”€ tests/             # Unit tests
â”œâ”€â”€ run.py             # Main launcher
â””â”€â”€ requirements.txt   # Dependencies
```

## ğŸ¯ Current Status

**Phase 1-2 Complete**: Project foundation and data collection system
- âœ… Basic hand detection with MediaPipe
- âœ… Data collection pipeline
- âœ… Data preprocessing system
- âœ… Machine learning model architecture
- âœ… Computer control actions
- âœ… Main application framework

**Next Steps**: 
- ğŸ”„ Collect real gesture data
- ğŸ”„ Train models on real data
- ğŸ”„ Improve gesture recognition accuracy
- ğŸ”„ Add more gesture types
- ğŸ”„ Enhance user interface

## ğŸ® Usage

### Basic Usage
```bash
python run.py
```

### Data Collection
```bash
python src/data_collection.py
```

### Testing
```bash
python scripts/test_data_collection.py
```

## âš™ï¸ Configuration

Edit `src/config.py` to customize:
- Gesture recognition settings
- Model parameters
- Action mappings
- Camera settings

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- MediaPipe for hand detection
- OpenCV for computer vision
- TensorFlow for machine learning

## ğŸ“§ Contact

For questions or feedback, please open an issue or contact me directly at adityakuchhal76@gmail.com.

Enjoy your journey towards touchless computing with Hand Helm!